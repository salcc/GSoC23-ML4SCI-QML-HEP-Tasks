{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83995870-a3cf-40b2-ab8d-af5a1074be47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GSoC 2023 ML4SCI QML-HEP Tasks\n",
    "\n",
    "MarÃ§al Comajoan Cara\n",
    "\n",
    "## Task II: Classical Graph Neural Network (GNN)\n",
    "\n",
    "### Task statement\n",
    "\n",
    "For task II, you will use ParticleNet's data for Quark/Gluon jet classification available at [1] with its corresponding description.\n",
    "- Choose 2 Graph-based architectures of your choice to classify jets as being quarks or gluons. Provide a description on what considerations you have taken to project this point-cloud dataset to a set of interconnected nodes and edges.\n",
    "- Discuss the resulting performance of the 2 chosen architectures. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15620fc-26d9-4ad9-a90d-a4ae3322215b",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The two graph-based architectures I decided to implement are Graph Convolutional Network (GCN) and ParticleNet.\n",
    "\n",
    "Firstly, I decided to implement the GCN, as introduced in the seminal paper [2][3], because it is one of the most popular graph neural network architectures and serves as the foundation for numerous other graph-based architectures. Secondly, I researched about what are the specific graph neural networks architectures for classifying jets, and I found a recent presentation about jet flavor identification at in the CMS Experiment at CERN [4], which compared several architectures and stated that ParticleNet [5][6] was the one obtaining the best results.\n",
    "\n",
    "I will implement both architectures using PyTorch [7], as it is my preferred deep learning library. I have opted not to utilize libraries such as PyTorch Geometric, which offer methods for training GNNs more easily, for example by including pre-built graph convolutional layers. My intention with this is to demonstrate how the architectures can be implemented from scratch.\n",
    "\n",
    "I also use the NumPy [8], SciPy 2-D sparse array  [9] and scikit-learn [10] libraries to perform some operations to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1cd3f2-63a8-4e81-86fd-ef883346a348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import sklearn.model_selection\n",
    "import sklearn.neighbors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def print_model_info(model):\n",
    "    print(model)\n",
    "    print(\"Number of trainable parameters:\",\n",
    "      sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "datasets_dir = os.path.expanduser(\"~/datasets\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e105f7-ec39-4b79-9b43-999d4ee7b131",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb61a20-85b8-48ab-8a8d-772d6bc3dbdd",
   "metadata": {},
   "source": [
    "The provided link [1] provides two data sets, each split in 20 files. One dataset contains charm and bottom jets and the other does not. Since here we just want to show how to apply GNNs to these data, we will only use the first file, which does not include the charm and bottom jets, and already provides many samples.\n",
    "\n",
    "The files are in .npz format, which can be loaded with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e60bda1-481c-4f23-857c-939fa8ae7fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', 'y']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(f'{datasets_dir}/QG_jets/QG_jets.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4798658e-c856-4195-87e6-4237318883c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs, labels = data['X'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a69fdc-3075-4069-9097-14fa802c4d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 139, 4), (100000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af487d6-b13e-4aae-b315-faf6cb070f7c",
   "metadata": {},
   "source": [
    "The dataset contains 100k jets, 50k are quark jets and 50k gluon jets, randomly sorted.\n",
    "\n",
    "139 is the max multiplicity of the jets in the file (other jets have been padded with zero-particles), and the features of each particle are its pt, rapidity, azimuthal angle, and pdgid.\n",
    "\n",
    "The labels are an 0 or 1 to indicate if they are gluon or quark jets, respectively.\n",
    "\n",
    "Now we perform the train-test split. We use 80% of the data for training and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8e6805-4e93-4650-b70f-204fe3b96069",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = sklearn.model_selection.train_test_split(inputs, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09a63b-99de-4f28-8311-6fd694f92731",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171a4b1c-5a2b-44db-9261-f89c33ef8c75",
   "metadata": {},
   "source": [
    "The data as we have it right now is not organized as a graph, which is what we need to apply a GNN. To project the dataset to a set of interconnected nodes and edges, for each jet we construct a graph where each point is a node, and it is connected by an undirected edge to its nearest neighbors. We use the spatial coordinates of the particles in the pseudorapidity-azimuth space, that is, the rapidity and azimuthal angle, which are the second and third features.\n",
    "\n",
    "We use the nearest neighbors algorithm from scikit-learn, which has a method to get the graph we want. The graph is returned in adjacency matrix format, using a SciPy compressed sparse row (csr) matrix, which is a data structure to store sparse arrays so that it occupies much less memory than storing the full $139\\times 139$ array.\n",
    "\n",
    "Then, we normalize the adjacency matrices using the procedure motivated in [2]:\n",
    "\n",
    "$$\\hat{A} = \\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}$$\n",
    "\n",
    "where $\\tilde{A}=A+I_N$ is the adjacency matrix of the graph with added self-connection, $I_N$ the identity matrix, and $\\tilde{D}=\\sum_j\\tilde{A}_{ij}$.\n",
    "\n",
    "Finally, we convert the SciPy csr matrices to PyTorch csr tensors, since this is the format we have to use to work with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "942ec0b0-38d2-4ba4-8809-8fb071302477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_graphs(features):\n",
    "    graphs = []\n",
    "    for x in features[:,:,1:3]:  # rapidity & azimuthal angle\n",
    "        # kneighbors_graph returns a SciPy csr matrix\n",
    "        adj_mat = sklearn.neighbors.NearestNeighbors().fit(x).kneighbors_graph(x).sorted_indices()\n",
    "\n",
    "        # normalize the adjacency matrix\n",
    "        adj_mat += scipy.sparse.eye(adj_mat.shape[0])\n",
    "        degree_matrix = scipy.sparse.diags(np.asarray(np.power(adj_mat.sum(axis=1), 0.5)).flatten())\n",
    "        adj_mat = degree_matrix @ adj_mat @ degree_matrix\n",
    "        \n",
    "        # now convert the SciPy csr matrices to PyTorch csr tensors\n",
    "        adj_mat = torch.sparse_csr_tensor(torch.tensor(adj_mat.indptr), torch.tensor(adj_mat.indices), torch.tensor(adj_mat.data),\n",
    "                                          size=torch.Size(adj_mat.shape), dtype=torch.float32)\n",
    "        \n",
    "        graphs.append(adj_mat)\n",
    "        \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf520c91-ae37-422a-b5da-8872e632ba11",
   "metadata": {},
   "source": [
    "We also convert the features and labels NumPy arrays to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5846def-c5c8-4629-a708-d6542de4bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(features, labels):\n",
    "    graphs = create_graphs(features)\n",
    "    features = torch.tensor(features, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return graphs, features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654d0057-cde4-469e-9edf-907410cf5d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_391697/1367554803.py:13: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  adj_mat = torch.sparse_csr_tensor(torch.tensor(adj_mat.indptr), torch.tensor(adj_mat.indices), torch.tensor(adj_mat.data),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((80000, torch.Size([139, 139])),\n",
       " torch.Size([80000, 139, 4]),\n",
       " torch.Size([80000]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = create_dataset(features_train, labels_train)\n",
    "test_set = create_dataset(features_test, labels_test)\n",
    "\n",
    "(len(train_set[0]), train_set[0][0].shape), train_set[1].shape, train_set[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1665da8-eb8c-49c0-8137-5c94d5c817e9",
   "metadata": {},
   "source": [
    "We see that for training we have 80000 samples. Each input to the model is composed of the $139\\times 139$ normalized adjacency matrix, and $139\\times 4$ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c59d673c-ee8d-42d7-b4b5-747f668e4129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39936"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_set[2] == 0).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a4c68-7c51-43f3-b3a9-38d4875d0e85",
   "metadata": {},
   "source": [
    "We observe that the data set is balanced, as almost half of the dataset is from one class, and the other half from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf74895-7027-44bb-af60-b270771546d8",
   "metadata": {},
   "source": [
    "Now let us define the graph convolution layer and the graph convolutional network!\n",
    "\n",
    "The graph convolutional network has two graph convolution layers with a dropout in between, and is followed by a readout layer and a final fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91726fc2-9873-41f9-a190-86b2e599202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (gc1): GraphConv()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gc2): GraphConv()\n",
      "  (lin): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Number of trainable parameters: 17281\n"
     ]
    }
   ],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_dim, out_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_dim))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1 / math.sqrt(self.weight.size(1))\n",
    "        nn.init.uniform_(self.weight, -stdv, stdv)\n",
    "        nn.init.uniform_(self.bias, -stdv, stdv)\n",
    "    \n",
    "    def forward(self, node_feats, adj_mat):\n",
    "        support = torch.mm(node_feats, self.weight)\n",
    "        output = torch.mm(adj_mat, support) + self.bias\n",
    "        return output\n",
    "    \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.gc1 = GraphConv(in_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.gc2 = GraphConv(hid_dim, hid_dim)\n",
    "        self.lin = nn.Linear(hid_dim, out_dim)\n",
    "    \n",
    "    def forward(self, node_feats, adj_mat):\n",
    "        x = self.gc1(node_feats, adj_mat)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.gc2(x, adj_mat)\n",
    "        x = x.relu()\n",
    "        \n",
    "        x = torch.mean(x, dim=0) # readout layer\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "gcn = GCN(inputs.shape[-1], 128, 1, 0.1).to(device)\n",
    "print_model_info(gcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbda987-eaa0-4bda-bcb3-1b883bff418a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Using 128 as the hidden layer dimension we obtain that we will need to train 17281 parameters.\n",
    "\n",
    "Now let us train the network. Since the model we defined does not support batched input, we will use a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25aca958-e246-4c8f-8ec5-396ec4c8ffd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " TRAINING\tAccuracy: 0.660875\n",
      " TESTING \tAccuracy: 0.661200\n",
      "Epoch 1\n",
      " TRAINING\tAccuracy: 0.664613\n",
      " TESTING \tAccuracy: 0.666950\n",
      "Epoch 2\n",
      " TRAINING\tAccuracy: 0.663963\n",
      " TESTING \tAccuracy: 0.666800\n",
      "Epoch 3\n",
      " TRAINING\tAccuracy: 0.663037\n",
      " TESTING \tAccuracy: 0.663050\n",
      "Epoch 4\n",
      " TRAINING\tAccuracy: 0.662388\n",
      " TESTING \tAccuracy: 0.661350\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_set, optimizer):\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for adj_mat, node_feats, label in zip(*train_set):\n",
    "        adj_mat, node_feats, label = adj_mat.to(device), node_feats.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(node_feats, adj_mat)\n",
    "        loss = criterion(out, label.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += ((F.sigmoid(out) > 0.5) == label).item()\n",
    "    return correct / len(train_set[1])\n",
    "    \n",
    "def test(model, device, test_set):\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for adj_mat, node_feats, label in zip(*test_set):\n",
    "            adj_mat, node_feats, label = adj_mat.to(device), node_feats.to(device), label.to(device)\n",
    "            out = model(node_feats, adj_mat)\n",
    "            correct += ((F.sigmoid(out) > 0.5) == label).item()\n",
    "    return correct / len(test_set[1])\n",
    "\n",
    "optimizer = torch.optim.Adam(gcn.parameters())\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f' TRAINING\\tAccuracy: {train(gcn, device, train_set, optimizer):.6f}')\n",
    "    print(f\" TESTING \\tAccuracy: {test(gcn, device, test_set):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437750d-e125-4155-a671-11ed8cd6b0f6",
   "metadata": {},
   "source": [
    "We observe that after the first epoch, the model does not improve much.\n",
    "\n",
    "The final test accuracy obtained is 66.14%. Let us see now if ParticleNet performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326854e-4d0e-4c5a-826e-bcdb277d6f3d",
   "metadata": {},
   "source": [
    "### ParticleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f8b4d-0146-4b1a-a6a7-960daa92a97b",
   "metadata": {},
   "source": [
    "ParticleNet also constructs the graph from the point cloud data with the approach we used for the GCN. However, in the original implementation this step is already included inside the network definition, in particular, it is performed inside the layer called `EdgeConv`.\n",
    "\n",
    "Nonetheless, we still have to separate the coordinates in a separated tensor from the features, which is what we do here, apart from converting from NumPy arrays to PyTorch tensors as before. We also permute the dimensions to have the order expected in the ParticleNet implementation, and create PyTorch Datasets and DataLoaders to train in batches, in particular of 32 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea362d99-d406-48ec-95b1-cba964e3ee45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(features, labels):\n",
    "    points = torch.tensor(features[:,:,1:3], dtype=torch.float32).permute(0, 2, 1)\n",
    "    features = torch.tensor(features, dtype=torch.float32).permute(0, 2, 1)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return torch.utils.data.TensorDataset(points, features, labels)\n",
    "\n",
    "train_set = create_dataset(features_train, labels_train)\n",
    "test_set = create_dataset(features_test, labels_test)\n",
    "\n",
    "train_dataloader =  torch.utils.data.DataLoader(train_set, batch_size=32)\n",
    "test_dataloader =  torch.utils.data.DataLoader(test_set, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759ba88-bcef-4664-abf8-6c4982be5eea",
   "metadata": {},
   "source": [
    "Now let us define the `EdgeConv` layer and ParticleNet!\n",
    "\n",
    "The architecture implemented is the same one as the original, except for the hyperparameter values, which are set so that the ParticleNet has a similar number of parameters to the GCN, to make the comparison more fair. In particular, we are using two `EdgeConv` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9bff85-8993-4bc9-a5ad-bcaae2317d98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParticleNet(\n",
      "  (bn_fts): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (edge_convs): ModuleList(\n",
      "    (0): EdgeConv(\n",
      "      (convs): ModuleList(\n",
      "        (0-2): 3 x Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (bns): ModuleList(\n",
      "        (0-2): 3 x BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (acts): ModuleList(\n",
      "        (0-2): 3 x ReLU()\n",
      "      )\n",
      "      (sc): Conv1d(4, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (sc_bn): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (sc_act): ReLU()\n",
      "    )\n",
      "    (1): EdgeConv(\n",
      "      (convs): ModuleList(\n",
      "        (0-2): 3 x Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (bns): ModuleList(\n",
      "        (0-2): 3 x BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (acts): ModuleList(\n",
      "        (0-2): 3 x ReLU()\n",
      "      )\n",
      "      (sc): Conv1d(8, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (sc_bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (sc_act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fusion_block): Sequential(\n",
      "    (0): Conv1d(24, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of trainable parameters: 21289\n"
     ]
    }
   ],
   "source": [
    "class EdgeConv(nn.Module):\n",
    "    def __init__(self, k, in_feat, out_feats):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(2 * in_feat if i == 0 else out_feats[i-1],\n",
    "                                              out_feats[i],\n",
    "                                              kernel_size=1,\n",
    "                                              bias=False)\n",
    "                                    for i in range(len(out_feats))])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm2d(out_feats[i])\n",
    "                                  for i in range(len(out_feats))])\n",
    "        self.acts = nn.ModuleList([nn.ReLU()\n",
    "                                   for i in range(len(out_feats))])\n",
    "        if in_feat == out_feats[-1]:\n",
    "            self.sc = None\n",
    "        else:\n",
    "            self.sc = nn.Conv1d(in_feat, out_feats[-1], kernel_size=1, bias=False)\n",
    "            self.sc_bn = nn.BatchNorm1d(out_feats[-1])\n",
    "        self.sc_act = nn.ReLU()\n",
    "\n",
    "    def forward(self, points, features):\n",
    "        # KNN\n",
    "        x = features\n",
    "        inner = -2 * torch.matmul(x.transpose(2, 1), x)\n",
    "        xx = torch.sum(x**2, dim=1, keepdim=True)\n",
    "        pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
    "        topk_indices = pairwise_distance.topk(k=self.k + 1, dim=-1)[1][:,:,1:]\n",
    "        \n",
    "        # Get graph features\n",
    "        x = features\n",
    "        batch_size, num_dims, num_points = features.shape\n",
    "        idx_base = torch.arange(0, batch_size, device=features.device).view(-1, 1, 1) * num_points\n",
    "        idx = topk_indices + idx_base\n",
    "        idx = idx.view(-1)\n",
    "        fts = x.transpose(2, 1).reshape(-1, num_dims)\n",
    "        fts = fts[idx,:].view(batch_size, num_points, self.k, num_dims)\n",
    "        fts = fts.permute(0, 3, 1, 2).contiguous()\n",
    "        x = x.view(batch_size, num_dims, num_points, 1).repeat(1, 1, 1, self.k)\n",
    "        x = torch.cat((x, fts - x), dim=1)\n",
    "        \n",
    "        # Apply EdgeConv\n",
    "        for conv, bn, act in zip(self.convs, self.bns, self.acts):\n",
    "            x = conv(x)\n",
    "            x = bn(x)\n",
    "            x = act(x)\n",
    "        \n",
    "        fts = x.mean(-1)\n",
    "        \n",
    "        if self.sc:\n",
    "            sc = self.sc(features)\n",
    "            sc = self.sc_bn(sc)\n",
    "        else:\n",
    "            sc = features\n",
    "        \n",
    "        return self.sc_act(sc + fts)\n",
    "    \n",
    "class ParticleNet(nn.Module):\n",
    "    def __init__(self, in_dims, out_dim, conv_params, fc_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn_fts = nn.BatchNorm1d(in_dims)\n",
    "        \n",
    "        self.edge_convs = nn.ModuleList([EdgeConv(conv_params[i][0],\n",
    "                                                  in_dims if i == 0 else conv_params[i-1][1][-1],\n",
    "                                                  conv_params[i][1])\n",
    "                                         for i in range(len(conv_params))])\n",
    "        \n",
    "        in_chn = sum(x[-1] for _, x in conv_params)\n",
    "        out_chn = np.clip((in_chn // 128) * 128, 128, 1024)\n",
    "        self.fusion_block = nn.Sequential(\n",
    "            nn.Conv1d(in_chn, out_chn, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(out_chn),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.ModuleList([nn.Sequential(nn.Linear(out_chn if i == 0 else fc_params[i-1][0],\n",
    "                                                         fc_params[i][0]),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Dropout(fc_params[i][1]))\n",
    "                                 for i in range(len(fc_params))])\n",
    "        self.fc.append(nn.Linear(fc_params[-1][0], out_dim))\n",
    "    \n",
    "    def forward(self, points, features):\n",
    "        mask = (features.abs().sum(dim=1, keepdim=True) != 0)\n",
    "        points *= mask\n",
    "        features *= mask\n",
    "        coord_shift = (mask == 0) * 1e9\n",
    "        \n",
    "        counts = mask.float().sum(dim=-1)\n",
    "        counts = torch.max(counts, torch.ones_like(counts))\n",
    "        \n",
    "        fts = self.bn_fts(features) * mask\n",
    "        \n",
    "        outputs = []\n",
    "        for i, conv in enumerate(self.edge_convs):\n",
    "            pts = (points if i == 0 else fts) + coord_shift\n",
    "            fts = conv(pts, fts) * mask\n",
    "            outputs.append(fts)\n",
    "        fts = self.fusion_block(torch.cat(outputs, dim=1)) * mask\n",
    "        \n",
    "        x = fts.sum(dim=-1) / counts\n",
    "        \n",
    "        for lyr in self.fc:\n",
    "            x = lyr(x)\n",
    "        return x\n",
    "\n",
    "particle_net = ParticleNet(4, 1, conv_params=[(5, (8, 8, 8)), (5, (16, 16, 16))], fc_params=[(128, 0.1)]).to(device)\n",
    "print_model_info(particle_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a40d8-8303-4236-8be1-07350fa71184",
   "metadata": {},
   "source": [
    "We will have to train 21289 parameters. Recall that the GCN trained had 17281."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ee37c-7dd1-4992-ae3c-23575815d2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now let us train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee33346-c3f4-4f5b-bcce-ff877a21927c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      " TRAINING\tAccuracy: 0.768575\n",
      " TESTING \tAccuracy: 0.781950\n",
      "Epoch 1\n",
      " TRAINING\tAccuracy: 0.776975\n",
      " TESTING \tAccuracy: 0.783450\n",
      "Epoch 2\n",
      " TRAINING\tAccuracy: 0.778737\n",
      " TESTING \tAccuracy: 0.784450\n",
      "Epoch 3\n",
      " TRAINING\tAccuracy: 0.780637\n",
      " TESTING \tAccuracy: 0.784100\n",
      "Epoch 4\n",
      " TRAINING\tAccuracy: 0.781450\n",
      " TESTING \tAccuracy: 0.784600\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_dataloader, optimizer):\n",
    "    correct = 0\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for points, features, label in train_dataloader:\n",
    "        points, features, label = points.to(device), features.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(points, features).squeeze()\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += ((F.sigmoid(out) > 0.5) == label).sum().item()\n",
    "    return correct / len(train_dataloader.dataset)\n",
    "    \n",
    "def test(model, device, test_dataloader):\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for points, features, label in test_dataloader:\n",
    "            points, features, label = points.to(device), features.to(device), label.to(device)\n",
    "            out = model(points, features).squeeze()\n",
    "            correct += ((F.sigmoid(out) > 0.5) == label).sum().item()\n",
    "    return correct / len(test_dataloader.dataset)\n",
    "\n",
    "optimizer = torch.optim.Adam(particle_net.parameters())\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f' TRAINING\\tAccuracy: {train(particle_net, device, train_dataloader, optimizer):.6f}')\n",
    "    print(f\" TESTING \\tAccuracy: {test(particle_net, device, test_dataloader):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13fe3d-fed2-4b09-b7ca-0b0caa261792",
   "metadata": {},
   "source": [
    "With ParticleNet we obtained an accuracy of 78.46% on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2af55b-0668-4798-a2bb-a0beaa509f95",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a05cf-811d-4dc2-951d-9eb225546e9b",
   "metadata": {},
   "source": [
    "The GCN obtained an accuracy of 66.14% while ParticleNet achieved an accuracy of 78.46%, which is an increase of 12.32%.\n",
    "\n",
    "Possibly, this increase is due to the architecture, which is more tailored for the task at hand. However, we also have to consider that the number of parameters in ParticleNet was slightly higher than in the GCN model.\n",
    "\n",
    "Perhaps we could achieve better accuracies in both models by using more data from the files we did not use and by performing hyperparameter optimization, but this is outside the scope of this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b171f3-9bbb-4a8d-9ed7-04badedf5ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8ec2b8-25bd-406e-9bbf-9ae41db8cb22",
   "metadata": {},
   "source": [
    "1. [Pythia8 Quark and Gluon Jets for Energy Flow data set (Zenodo)](https://zenodo.org/record/3164691#.YigdGt9MHrB)\n",
    "2. [Thomas N. Kipf, Max Welling. Semi-Supervised Classification with Graph Convolutional Networks (2017)](https://arxiv.org/abs/1609.02907)\n",
    "3. [Graph Convolutional Networks in PyTorch (Thomas Kipf GitHub)](https://github.com/tkipf/pygcn)\n",
    "4. [Loukas Gouskos. Jet flavor identification using Graph Neural Networks in CMS (2022)](https://indico.cern.ch/event/1201307/attachments/2522301/4337334/lg-cernds-gnntaggingcms_v2.pdf)\n",
    "5. [Huilin Qu, Loukas Gouskos. ParticleNet: Jet Tagging via Particle Clouds (2020)](https://arxiv.org/abs/1902.08570)\n",
    "6. [ParticleNet (CMS Machine Learning Documentation)](https://cms-ml.github.io/documentation/inference/particlenet.html)\n",
    "7. [PyTorch](https://pytorch.org/)\n",
    "8. [NumPy](https://numpy.org/)\n",
    "9. [SciPy sparse matrices documentation](https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "10. [scikit-lern](https://scikit-learn.org/stable/index.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
